


import pandas as pd
import re
from urllib.parse import urlparse
from collections import Counter





df = pd.read_csv('../data/interim/partial_cleaned.csv', index_col=0)


df.reset_index(drop=True, inplace=True)


df


df['count_slash'] = df['URL'].str.count('/')


df[(df['count_slash'] == 2) & (df['label'] == 1)]


df[(df['count_slash'] <= 1) & (df['label'] == 1)]


df[(df['count_slash'] == 2) & (df['label'] == 0)]


df.drop(columns=['count_slash'], inplace=True)














def url_length_without_spaces(url):
    # Remove all whitespace from the URL
    url_no_spaces = ''.join(url.split())
    # Return the length of the cleaned URL
    return len(url_no_spaces)

# Apply this function to the 'URL' column in your DataFrame
df['url_length_len'] = df['URL'].apply(url_length_without_spaces)


df['length_diff'] = df['URLLength'] - df['url_length_len']


df[df['length_diff'] <= -2]





df[df['length_diff'] >= 1]





df[df['length_diff'] == 0]


df[(df['length_diff'] == 0) & (df['URL'].str.startswith('https://www'))]


df[df['length_diff'] == -1]





def url_length_regex(url):
    '''Matching the entire URL using a regular expression and counting the number of characters'''
    match = re.match(r".*", url)
    return len(match.group(0)) if match else 0

df['url_len_regex'] = df['URL'].apply(url_length_regex)


df['lenght_diff_reg'] = df['URLLength'] - df['url_len_regex']


df[df['length_diff'] - df['lenght_diff_reg'] != 0]  # regex returns same result as len.


def url_length_encoded(url):
    '''Calculating the byte size of the URL when encoded (useful if the URL contains special characters)'''
    return len(url.encode('utf-8'))

df['url_len_encode'] = df['URL'].apply(url_length_encoded)


df['lenght_diff_encode'] = df['URLLength'] - df['url_len_encode']


df[df['length_diff'] - df['lenght_diff_encode'] != 0]  # encode('utf-8') returns same result as len.


def url_length_parsed(url):
    '''Splitting the URL into its components and summing up the lengths of each part'''
    parsed = urlparse(url)
    # Calculate the length as the sum of all URL components
    return sum(len(part) for part in [parsed.scheme, parsed.netloc, parsed.path, parsed.params, parsed.query, parsed.fragment])

df['url_len_parsed'] = df['URL'].apply(url_length_parsed)


df['lenght_diff_parsed'] = df['URLLength'] - df['url_len_parsed']


df[df['length_diff'] - df['lenght_diff_parsed'] != 0]  # urlparsed returns diff result from len.


# The difference arises because the parsed method does not include characters like /, :, ?, #, or ; that act as separators between the components. 
# These are treated as structural elements, not part of the actual content length.


def url_length_counter(url):
    '''Counting all characters in the URL and sum up the frequencies'''
    char_counts = Counter(url)
    return sum(char_counts.values())

df['url_len_counter'] = df['URL'].apply(url_length_counter)


df['lenght_diff_counter'] = df['URLLength'] - df['url_len_counter']


df[df['length_diff'] - df['lenght_diff_counter'] != 0]  # Counter returns same result as len.





sum(df['label'] == 1) # Benign urls


sum(df['label'] == 0) # Malicious urls


df[(df['length_diff'] == 0) & (df['label'] == 1)] # This means every Benign url has -1 difference.


df[(df['length_diff'] == 0) & (df['label'] == 0)]


df[(df['length_diff'] == -1) & (df['label'] == 1)]


df[(df['length_diff'] == -1) & (df['label'] == 0)]


df





# To get the index of the starting column
start_index = df.columns.tolist().index('length_diff')


columns_to_drop = df.columns.tolist()[start_index:]


df.drop(columns=columns_to_drop, inplace=True)


df





def count_letters_in_url(url):
    # Step 1: Remove all instances of 'http', 'https', and 'www' from the URL
    cleaned_url = re.sub(r'http|https|www', '', url, flags=re.IGNORECASE)
    
    # Step 2: Extract and count only alphabetic characters
    letters_only = re.findall(r'[a-zA-Z]', cleaned_url)
    
    return len(letters_only)

df['num_letters'] = df['URL'].apply(count_letters_in_url)


df['num_letters_diff'] = df['NoOfLettersInURL'] - df['num_letters']


df[df['num_letters_diff'] == 0]


df[df['num_letters_diff'] != 0]


df[df['num_letters_diff'] == -1]


df[df['num_letters_diff'] == -2]


df[df['num_letters_diff'] == -3]


def find_common_word(df, rows, word_length):
    """
    Finds the common word of specified length in selected rows of a DataFrame containing URLs.
    
    Parameters:
    - df: DataFrame containing a column 'URL'.
    - rows: List of row indices to compare.
    - word_length: The length of the word to find.
    
    Returns:
    - A set of common words of the specified length.
    """
    # Extract URLs from specified rows
    urls = df.loc[rows, 'URL']
    
    # Extract words of the specified length from each URL
    word_sets = []
    for url in urls:
        # Find all words of the specified length (words are sequences of alphanumeric characters)
        words = set(re.findall(rf'\b[a-zA-Z0-9]{{{word_length}}}\b', url))
        word_sets.append(words)
    
    # Find the intersection of all sets to get common words
    common_words = set.intersection(*word_sets) if word_sets else set()
    
    return common_words

# Find common words of length ** in rows *, **, ***
rows_to_compare = [4362, 9409, 12866, 14841, 19511, 25987, 28376, 39571,67118, 69854]
word_length = 5
common = find_common_word(df, rows_to_compare, word_length)

print(f"Common words of length {word_length}: {common}")











df.iloc[226902, 0]


df[df['num_letters_diff'] == -4]


df[(df['num_letters_diff'] == -4) & (df['label'] == 0)]


df.iloc[23809, 0]


df.iloc[23809, 0]


df.iloc[111323, 0]


def find_common_word(df, rows, word_length):
    """
    Finds the common word of specified length in selected rows of a DataFrame containing URLs.
    
    Parameters:
    - df: DataFrame containing a column 'URL'.
    - rows: List of row indices to compare.
    - word_length: The length of the word to find.
    
    Returns:
    - A set of common words of the specified length.
    """
    # Extract URLs from specified rows
    urls = df.loc[rows, 'URL']
    
    # Extract words of the specified length from each URL
    word_sets = []
    for url in urls:
        # Find all words of the specified length (words are sequences of alphanumeric characters)
        words = set(re.findall(rf'\b[a-zA-Z0-9]{{{word_length}}}\b', url))
        word_sets.append(words)
    
    # Find the intersection of all sets to get common words
    common_words = set.intersection(*word_sets) if word_sets else set()
    
    return common_words

# Find common words of length ** in rows *, **, ***
rows_to_compare = [23809, 111323, 111643, 121284, 126723, 162367]
word_length = 6
common = find_common_word(df, rows_to_compare, word_length)

print(f"Common words of length {word_length}: {common}")

















df[df['num_letters_diff'] <= -5]


df.iloc[103102, 0]


df.iloc[1086, 0]


df.iloc[1198, 0]


df.drop(columns=['num_letters_diff'], inplace=True)

















def count_digits_in_url(url):
    return len(re.findall(r'\d', url))

df['num_digits'] = df['URL'].apply(count_digits_in_url)


df['num_digits_diff'] = df['NoOfDegitsInURL'] - df['num_digits'] 


df[df['num_digits_diff'] == 0]


df[df['num_digits_diff'] == -1]





df.iloc[674, 0]


df.drop(columns=['num_digits_diff'], inplace=True)














def count_special_chars_in_url(url):
    # Regular expression to find any character that is not alphanumeric or basic punctuation
    return len(re.findall(r'[^a-zA-Z0-9/?&=.]', url))

# Apply the function to the DataFrame
df['num_rest_special_char'] = df['URL'].apply(count_special_chars_in_url)


df['num_rest_special_char_diff'] = df['NoOfOtherSpecialCharsInURL'] - df['num_rest_special_char'] 


df[df['num_rest_special_char_diff'] == 0]


df.iloc[146085, 0]


df.iloc[170541, 0]


df[df['num_rest_special_char_diff'] < 0]


df.iloc[6927, 0]


df.iloc[228083, 0]


df[df['num_rest_special_char_diff'] < -20]


df.iloc[91678, 0]





df[df['num_rest_special_char_diff'] >= 1]


df[df['num_rest_special_char_diff'] == 1]


df[df['num_rest_special_char_diff'] == 2]


df[df['num_rest_special_char_diff'] >= 20]


df.iloc[5137, 0]


def find_repeated_elements(url, repeat_count):
    # Count occurrences of each character in the URL
    char_count = Counter(url)
    # Filter elements repeated the specified number of times
    repeated_elements = {char: count for char, count in char_count.items() if count == repeat_count}
    return repeated_elements

# Example: Specify the row index and repeat count
url = df.iloc[5137, 0]  # Replace with your specific index
repeat_count = 1        # Replace with your desired repeat count

# Find repeated elements
repeated_elements = find_repeated_elements(url, repeat_count)

# Display the result
print(f"In URL: {url}")
print(f"Elements repeated {repeat_count} times: {repeated_elements}")





df[(df['num_rest_special_char_diff'] == 4) & (df['label'] == 1)]


df.iloc[25, 0]





df[df['num_rest_special_char_diff'] == 5]


df[df['num_rest_special_char_diff'] == 6]


df[df['num_rest_special_char_diff'] == 7]


df[df['num_rest_special_char_diff'] == 8]


df[df['num_rest_special_char_diff'] == 9]


df.iloc[154, 0]


df.iloc[4616, 0]


df[df['num_rest_special_char_diff'] == 10]


df.iloc[349, 0]


df.drop(columns=['num_rest_special_char_diff'], inplace=True)



